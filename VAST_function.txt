import numpy as np
import pyroomacoustics as pra
from scipy.io import wavfile
from scipy.signal import fftconvolve
from scipy.linalg import toeplitz, eigh
import matplotlib.pyplot as plt
import time
import os

# --- 1. CORE HELPER FUNCTIONS ---

def _generate_mic_grid(room_dim):
    """
    Helper function to generate microphone positions and corresponding 
    bright/dark zone indices based on room dimensions.
    
    Args:
        room_dim (list): [L, W, H] dimensions of the room.

    Returns:
        tuple: (mic_positions_list, bright_indices, dark_indices)
    """
    mic_positions_list = []
    bright_indices = []
    dark_indices = []

    idx = 0
    room_center_x = room_dim[0] / 2

    # Left half (Bright zone)
    # Using 6x4 grid for a total of 24 mics
    for x_m in np.linspace(0.5, room_center_x - 0.5, 6):
        for y_m in np.linspace(0.5, room_dim[1] - 0.5, 4):
            mic_positions_list.append([x_m, y_m, 1.5])
            bright_indices.append(idx)
            idx += 1

    # Right half (Dark zone)
    # Using 6x4 grid for a total of 24 mics
    for x_m in np.linspace(room_center_x + 0.5, room_dim[0] - 0.5, 6):
        for y_m in np.linspace(0.5, room_dim[1] - 0.5, 4):
            mic_positions_list.append([x_m, y_m, 1.5])
            dark_indices.append(idx)
            idx += 1

    return mic_positions_list, bright_indices, dark_indices

def setup_acoustic_scenario(sources, 
                            mic_positions_list, 
                            bright_zone_mics_index, 
                            dark_zone_mics_index, 
                            fs_target, 
                            room_dim, 
                            absorption, 
                            max_order):
    """
    Sets up a pyroomacoustics simulation environment (ShoeBox) and computes RIRs.
    
    Returns:
        tuple: (IR, M_b, M_d)
            IR (list of lists): Room Impulse Responses.
            M_b (int): Number of bright zone microphones.
            M_d (int): Number of dark zone microphones.
    """
    sources_list = sources 

    M_b, M_d = len(bright_zone_mics_index), len(dark_zone_mics_index)
    
    # Define Room
    room = pra.ShoeBox(
        room_dim,
        fs=fs_target,
        materials=pra.Material(absorption),
        max_order=max_order,
    )

    # Add Sources (Loudspeakers)
    for s in sources_list:
        room.add_source(s)

    # Define and Add Microphone Grid
    mic_positions = np.array(mic_positions_list).T
    mic_array = pra.MicrophoneArray(
        mic_positions,
        room.fs)
    room.add_microphone_array(mic_array)

    # Compute RIRs
    print(f"Computing RIRs for {mic_positions.shape[1]} mics (Bright: {M_b}, Dark: {M_d}) and {len(sources_list)} sources...")
    room.compute_rir()

    # RIRs are stored in room.rir: room.rir[mic_index][source_index]
    IR = room.rir 
    
    return IR, M_b, M_d

def build_U_ml_single(x, h_ml, N, J):
    """ Build U^{m,l} (N x J) for a single mic m and single speaker l (Toeplitz matrix). """
    # u = x * h_ml (full conv), truncated to N samples
    u = fftconvolve(x, h_ml)[:N]
    if u.shape[0] < N:
        u = np.pad(u, (0, N - u.shape[0]))
    
    # Create the Toeplitz matrix (first column is u, first row is zeros of length J)
    first_col = u
    first_row = np.zeros(J)
    U_ml = toeplitz(first_col, first_row)[:N, :J]
    return U_ml

def build_Um_for_mic(m_idx, x, IR, N, J, n_srcs):
    """ 
    Build U^m for microphone index m_idx by horizontally concatenating U^{m,l} for all l.
    Returns U_m (N x (L*J)).
    """
    U_blocks = []
    for l in range(n_srcs):
        h_ml = IR[m_idx][l]
        U_ml = build_U_ml_single(x, h_ml, N, J)
        U_blocks.append(U_ml)
    U_m = np.hstack(U_blocks)
    return U_m

def build_R_from_micset(mic_indices, x, IR, N, J, n_srcs, reg_eps=0):
    """
    Compute R = (1/|M|) * sum_{m in M} U^m.T @ U^m 
    R is the average covariance approximation over the microphones in the set.
    """
    LJ = n_srcs * J
    R = np.zeros((LJ, LJ), dtype=float)
    
    for m in mic_indices:
        U_m = build_Um_for_mic(m, x, IR, N, J, n_srcs)
        R += U_m.T @ U_m
        
    R /= max(1, len(mic_indices))
    
    # Apply regularization if needed (for R_D)
    if reg_eps > 0:
        R += reg_eps * np.eye(LJ)
        
    return R

def compute_rB(bright_mics_index, x, IR, d_B, N, J, n_srcs):
    """ Compute the cross-correlation vector r_B = E[U_B^T d_B] """
    LJ = n_srcs * J
    r_B = np.zeros((LJ,), dtype=float)

    for mi, m in enumerate(bright_mics_index):
        U_m = build_Um_for_mic(m, x, IR, N, J, n_srcs)  # (N, LJ)
        d_vec = d_B[:, mi]                              # (N,)
        r_B += U_m.T @ d_vec                            # (LJ,)

    # Normalize by the total number of data points
    r_B /= (len(bright_mics_index) * N)

    return r_B

def compute_q_vast(V, mu, lambda_vals, U, r_B):
    """ Compute the VAST filter vector q """
    q = np.zeros_like(r_B)
    for v in range(V):
        weight = lambda_vals[v] / (lambda_vals[v] + mu)
        projection = np.dot(U[:, v].T, r_B)
        q += weight * projection * U[:, v]
    return q

# --- 2. MAIN DESIGN FUNCTION ---

def design_vast_td_filter(sources, mic_positions_list, bright_zone_mics_index, dark_zone_mics_index,
                          wav_path, out_q_path, fs_target=16000, J=256, N=2000, 
                          V=4, mu=0.5, room_dim=[6.0, 3.0, 3.5], absorption=0.2, 
                          max_order=10, reg_eps=1e-6, target_amplitude=0.3536):
    """
    Designs the VAST Time-Domain filter coefficients (q_matrix) and saves them.

    Args (Acoustic Setup):
        sources (list of lists): Coordinates of the sound sources (loudspeakers).
        mic_positions_list (list of lists): Coordinates of all microphones.
        bright_zone_mics_index (list): Indices (0-based) of mics in the bright zone.
        dark_zone_mics_index (list): Indices (0-based) of mics in the dark zone.
        
    Args (Parameters):
        wav_path (str): Path to the excitation .wav file.
        out_q_path (str): Path to save the resulting q_matrix (.npy).
        fs_target (int): Sampling rate for RIR simulation and signal processing.
        J (int): Filter length (number of taps) per loudspeaker.
        N (int): Number of time samples used for covariance matrix estimation.
        V (int): Number of dominant eigenmodes to use in the VAST solution.
        mu (float): Regularization parameter for VAST.
        room_dim (list): [L, W, H] dimensions of the room (meters).
        absorption (float): Wall absorption coefficient for RIR simulation.
        max_order (int): Maximum reflections for RIR computation.
        reg_eps (float): Regularization factor for R_D (dark zone covariance).
        target_amplitude (float): Constant amplitude for the desired bright zone signal d_B.

    Returns:
        np.ndarray: The resulting filter coefficient matrix q_matrix (L x J).
    """

    print("--- Starting VAST Time-Domain Filter Design ---")
    t_start_total = time.perf_counter()

    # --- Load and Prepare Signal (x) ---
    if not os.path.exists(wav_path):
        raise FileNotFoundError(f"{wav_path} not found - adjust path.")
    fs_wav, wav = wavfile.read(wav_path)
    
    if fs_wav != fs_target:
        print(f"Warning: wav sample rate {fs_wav} != target {fs_target}. This implementation does not resample.")

    wav = np.array(wav, dtype=float)
    if wav.ndim > 1:
        wav = wav[:, 0]
    wav = wav / (np.max(np.abs(wav)) + 1e-12)
    x = wav[:N].copy() if len(wav) >= N else np.pad(wav, (0, max(0, N-len(wav))), mode='constant')

    # --- Setup Acoustic Scenario and Compute RIRs ---
    n_srcs = len(sources)
    n_mics = len(mic_positions_list)
    
    IR, M_b, M_d = setup_acoustic_scenario(
        sources=sources, 
        mic_positions_list=mic_positions_list, 
        bright_zone_mics_index=bright_zone_mics_index, 
        dark_zone_mics_index=dark_zone_mics_index,
        fs_target=fs_target, room_dim=room_dim, absorption=absorption, max_order=max_order
    )
    
    # --- Compute Covariance Matrices R_B and R_D ---
    tstart = time.perf_counter()
    R_B = build_R_from_micset(bright_zone_mics_index, x, IR, N, J, n_srcs, reg_eps=0)
    R_D = build_R_from_micset(dark_zone_mics_index, x, IR, N, J, n_srcs, reg_eps=reg_eps)
    print("Built R_B and R_D in {:.2f} s".format(time.perf_counter() - tstart))

    # --- Solve Generalized Eigenvalue Problem (GEP) ---
    print("Solving Generalized Eigenvalue Problem...")
    lambda_vals, U = eigh(R_B, R_D)

    # Sort eigenvalues descending
    idx = np.argsort(-lambda_vals.real)
    lambda_vals = lambda_vals.real[idx]
    U = U[:, idx]
    
    # Check V (number of modes) vs total modes
    V = min(V, len(lambda_vals))
    print(f"Using V={V} modes for VAST solution.")

    # --- Compute VAST Filter Vector (q) ---
    
    # Define desired signal d_B (constant amplitude across time/mics)
    d_B = np.ones((N, M_b)) * target_amplitude
    
    r_B = compute_rB(bright_zone_mics_index, x, IR, d_B, N, J, n_srcs)
    
    q_vec = compute_q_vast(V, mu, lambda_vals, U, r_B)
    
    # Reshape q vector into a matrix (Loudspeakers x Taps)
    q_matrix = q_vec.reshape(n_srcs, J)

    # --- Save Coefficients ---
    np.save(out_q_path, q_matrix)
    print(f"Successfully designed filter and saved q_matrix to {out_q_path} in {time.perf_counter() - t_start_total:.2f} s")
    
    return q_matrix

# --- 3. VISUALIZATION FUNCTION (Optional) ---

def visualize_pressure_field(q_matrix, wav_path, fs_target, sources, room_dim, 
                             grid_res=50, z_plane=1.5):
    """
    Computes and plots the RMS pressure field using a direct-path approximation 
    for visualization purposes.
    """
    L = q_matrix.shape[0]

    # Load test signal (use a short segment for visualization speed)
    fs_wav, wav = wavfile.read(wav_path)
    if wav.ndim > 1: wav = wav[:, 0]
    wav = np.array(wav, dtype=float)
    wav = wav / (np.max(np.abs(wav)) + 1e-12)
    test_signal = wav[:fs_target // 4] if len(wav) >= fs_target // 4 else wav
    
    x_grid = np.linspace(0, room_dim[0], grid_res)
    y_grid = np.linspace(0, room_dim[1], grid_res)
    X, Y = np.meshgrid(x_grid, y_grid, indexing='ij')
    Gx, Gy = X.shape
    pressure_field = np.zeros_like(X, dtype=float)
    
    speed_of_sound = 343.0

    print("\nComputing pressure field (coarse grid for speed)...")
    tstart = time.perf_counter()

    for ix in range(Gx):
        for iy in range(Gy):
            point = np.array([X[ix,iy], Y[ix,iy], z_plane])
            p_sum_sq = 0.0 # Using squared sum for coherent approximation (simpler here)
            
            # Sum the pressure contribution from each loudspeaker
            
            # --- CONVOLVE DRIVE SIGNALS (d_l) ---
            # d_l = x * q_l
            drives = [fftconvolve(test_signal, q_matrix[l])[:len(test_signal)] for l in range(L)]
            
            # --- CONVOLVE WITH PATH (h_l) ---
            total_pressure = np.zeros_like(drives[0])
            for l in range(L):
                src_pos = np.array(sources[l])
                r = np.linalg.norm(point - src_pos)
                
                # Approximate acoustic path (direct path only 1/r)
                if r > 1e-6:
                    h_val = 1.0 / r 
                else:
                    h_val = 1.0 
                    
                # Time delay
                delay = int(round(r * fs_target / speed_of_sound))
                
                # Apply delay and gain
                out_l = np.roll(drives[l], delay) * h_val
                out_l[:delay] = 0.0 # Zero out wrapped part

                total_pressure += out_l
            
            # RMS value of the total pressure waveform
            pressure_field[ix,iy] = np.sqrt(np.mean(total_pressure**2))
    
    print("Pressure computed in {:.2f}s".format(time.perf_counter() - tstart))

    # Compute averages for bright/dark masks
    room_center_x = room_dim[0] / 2
    bright_mask = X < room_center_x
    dark_mask = ~bright_mask
    
    avg_bright = np.mean(pressure_field[bright_mask])
    avg_dark = np.mean(pressure_field[dark_mask])
    
    print(f"Average pressure (bright) = {avg_bright:.6f} ; (dark) = {avg_dark:.6f}")
    contrast_db = 20.0 * np.log10((avg_bright + 1e-12) / (avg_dark + 1e-12))
    print(f"Contrast (bright/dark) [dB] = {contrast_db:.2f}")

    # Plot relative SPL
    P_db = 20.0 * np.log10(pressure_field / (np.max(pressure_field) + 1e-12) + 1e-12)
    
    plt.figure(figsize=(8,6))
    plt.imshow(P_db.T, origin='lower', extent=[0, room_dim[0], 0, room_dim[1]], cmap='inferno', aspect='auto')
    plt.colorbar(label='Relative dB')
    plt.scatter([s[0] for s in sources], [s[1] for s in sources], c='cyan', marker='*', s=100, edgecolors='k', label='Loudspeakers')
    
    # Add Bright/Dark zone markers
    plt.plot([room_center_x, room_center_x], [0, room_dim[1]], 'w--', linewidth=1, label='Zone Boundary')
    plt.text(room_center_x / 2, room_dim[1] * 0.9, 'Bright Zone', color='white', ha='center', fontsize=10, weight='bold')
    plt.text(room_center_x + (room_dim[0] - room_center_x) / 2, room_dim[1] * 0.9, 'Dark Zone', color='white', ha='center', fontsize=10, weight='bold')

    plt.title('Relative SPL (dB) at z={:.2f} m (VAST Filter Result)'.format(z_plane))
    plt.xlabel('x (m)')
    plt.ylabel('y (m)')
    plt.legend()
    plt.tight_layout()
    plt.show()
